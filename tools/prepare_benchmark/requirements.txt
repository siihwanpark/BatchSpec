torch==2.9.0+cu128
vllm
transformers
datasets
flashinfer-python